# pi-llm
Run large language models locally on a Raspberry Pi Zero 2W (512 MB RAM) using llama.cpp, swap, and aggressive quantization.
